{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "# filename=raw_input(\"enter file name:\")\n",
    "# testname=raw_input(\"test file: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../input_data/train.csv')\n",
    "# print data\n",
    "test=pd.read_csv('../input_data/sample_test.csv')\n",
    "#splitting randomly in 80:20 ratio\n",
    "data = data.sample(frac=1)\n",
    "train, validate = np.split(data, [int(.8*len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate entropy of 'left' for complete dataset under consideration\n",
    "def calculate_entropy(train):\n",
    "    values=train.left.unique()\n",
    "    entropy_node=0\n",
    "    for v in values:\n",
    "        num=train.left.value_counts()[v]\n",
    "        deno=len(train.left)\n",
    "        fraction=float(num)/deno\n",
    "        if fraction!=0:\n",
    "            entropy_node+=-(fraction*np.log2(fraction))\n",
    "    return entropy_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the purpose of training only on categorical data\n",
    "df=pd.DataFrame(train,columns=['Work_accident','left','promotion_last_5years','sales','salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if outlook is made root then find the entropy_attribute for overcast,sunny and rainy\n",
    "def entropy_attribute(df,attribute,original):\n",
    "    variables=df[attribute].unique()\n",
    "    values=df[original].unique()\n",
    "    entropy_attribute=0\n",
    "    I=0\n",
    "    for v in variables:\n",
    "        entropy_attribute=0\n",
    "        n=df[attribute].value_counts()[v]\n",
    "        d=len(df[attribute])\n",
    "        for x in values:\n",
    "            num=len(df[attribute][df[attribute]==v][df[original]==x])\n",
    "            deno=len(df[attribute][df[attribute]==v])\n",
    "            fraction=float(num)/deno\n",
    "            if fraction!=0:\n",
    "                entropy_attribute+=-(fraction*np.log2(fraction))\n",
    "        I+=(float(n)/d)*entropy_attribute\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Work_accident','left','promotion_last_5years','sales','salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the column causing max gain\n",
    "def max_gain(df):\n",
    "    p=\"\"\n",
    "    m=0\n",
    "    for i in df.columns:\n",
    "        gain=0\n",
    "        if i!='left':\n",
    "            gain=calculate_entropy(df)-entropy_attribute(df,i,'left')\n",
    "            if m < gain:\n",
    "                m=gain\n",
    "                p=i\n",
    "    return m,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decisionTree():\n",
    "    def __init__(self,name,df):\n",
    "        self.lable=name\n",
    "        self.child={}\n",
    "        self.positive=len(df[name][df['left']==1])\n",
    "        self.negative=len(df[name][df['left']==0])\n",
    "        self.isLeaf=False\n",
    "    def set_child(self,ch):\n",
    "        self.child=ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTree(df):\n",
    "    if len(df.columns)<=1:\n",
    "        leaf=decisionTree('left',df)\n",
    "        leaf.isLeaf=True\n",
    "        return leaf\n",
    "    \n",
    "    #select the label having highest gain and make it root\n",
    "    gain,lable=max_gain(df)\n",
    "    es=calculate_entropy(df)\n",
    "#     print gain,es\n",
    "#     if gain==0 and es!=0:\n",
    "#         print \"yes i am here\"\n",
    "\n",
    "    #if gain==0 then exit\n",
    "    if gain==0:\n",
    "        leaf=decisionTree('left',df)\n",
    "        leaf.isLeaf=True\n",
    "        return leaf\n",
    "    \n",
    "    \n",
    "    root=decisionTree(lable,df)\n",
    "    \n",
    "    #child for outlook would be outcast, sunny and rainy\n",
    "    childs=df[lable].unique()\n",
    "    children={}\n",
    "    df2=df\n",
    "    for i in childs:\n",
    "        rows=df2[df2[lable]==i]\n",
    "        rows=rows.drop(columns=[lable])\n",
    "        ch_root=buildTree(rows)\n",
    "        children[i]=ch_root\n",
    "    root.set_child(children)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root=buildTree(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(root):\n",
    "    if len(root.child)==0:\n",
    "        print \"return root: \",root.lable\n",
    "        return\n",
    "    \n",
    "    print \"Root: \",root.lable, root.isLeaf#, root.child\n",
    "    \n",
    "    for k,v in root.child.items():\n",
    "        print \"root: \",root.lable, \"key: \",k\n",
    "        if v!=None:\n",
    "            traverse(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,X):\n",
    "    root=model\n",
    "    row=X\n",
    "    #if leaf is reached then declare result\n",
    "    if root.isLeaf==True:\n",
    "        if root.positive > root.negative:\n",
    "            return \"YES\"\n",
    "        else:\n",
    "            return \"NO\"\n",
    "        \n",
    "    \n",
    "    row1=row\n",
    "    \n",
    "    #go to the children of selected node\n",
    "    ch_node=root.child[row1[root.lable]]\n",
    "    \n",
    "    if ch_node!=None:\n",
    "        if ch_node.lable=='left':\n",
    "            if ch_node.positive>ch_node.negative:\n",
    "                return \"YES\"\n",
    "            else:\n",
    "                return \"NO\"\n",
    "    #if child_node == None, then declare result\n",
    "    if ch_node==None:\n",
    "        if root.positive > root.negative:\n",
    "            return \"YES\"\n",
    "        else:\n",
    "            return \"NO\"\n",
    "    return predict(ch_node,row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df):\n",
    "    tn=0\n",
    "    tp=0\n",
    "    fn=0\n",
    "    fp=0\n",
    "    for index,rows in df.iterrows():\n",
    "        predicted_val=predict(root,rows)\n",
    "        if rows['left']==1 and predicted_val==\"YES\":\n",
    "            tp+=1\n",
    "        if rows['left']==0 and predicted_val==\"NO\":\n",
    "            tn+=1\n",
    "        if rows['left']==1 and predicted_val==\"NO\":\n",
    "            fn+=1\n",
    "        if rows['left']==0 and predicted_val==\"YES\":\n",
    "            fp+=1\n",
    "    accuracy=((tp+tn)/(tp+tn+fp+fn))*100\n",
    "    if tp+fn!=0:\n",
    "        recall=(tp/(tp+fn))*100\n",
    "    else:\n",
    "        recall=0\n",
    "    if tp+fp!=0:\n",
    "        precision=(tp/(tp+fp))*100\n",
    "    else:\n",
    "        precision=0\n",
    "    if recall!=0 and precision!=0:\n",
    "        f1score=(2/((1/recall)+(1/precision)))\n",
    "    else:\n",
    "        f1score=0\n",
    "    print \"True Positive: \"+str(tp)\n",
    "    print \"True Negative: \"+str(tn)\n",
    "    print \"False Positve: \"+str(fp)\n",
    "    print \"False Negative: \"+str(fn)\n",
    "    print \"accuracy: \"+str(accuracy)+\"%\"\n",
    "    print \"precision: \"+str(precision)+\"%\"\n",
    "    print \"recall: \"+str(recall)+\"%\"\n",
    "    print \"f1 score: \",f1score\n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 0\n",
      "True Negative: 1733\n",
      "False Positve: 0\n",
      "False Negative: 515\n",
      "accuracy: 77.090747331%\n",
      "precision: 0%\n",
      "recall: 0.0%\n",
      "f1 score:  0\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO\n",
      "NO\n"
     ]
    }
   ],
   "source": [
    "for index, row in test.iterrows():\n",
    "    print predict(root,row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
